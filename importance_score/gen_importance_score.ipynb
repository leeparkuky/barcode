{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "from fisher_simulation import *\n",
    "from importance_score import dask_parameter_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_sizes = [500, 1_000, 5_000, 10_000]\n",
    "error_scales = [1, sqrt(2), sqrt(5), sqrt(10)]\n",
    "\n",
    "subsample_size_x_error_scales = list(product(subsample_sizes, error_scales))\n",
    "# for sample_size, error_scale in tqdm(subsample_size_x_error_scales):\n",
    "#     single_simulation(sample_size = sample_size, iter = 5, error_scale = error_scale, ddf = ddf, num_interactions = num_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet('../simulation_with_2_interactions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = gen_subsample(500, 1, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_run = dask_parameter_generator(subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:19<00:00, 18.14it/s]  \n"
     ]
    }
   ],
   "source": [
    "test_run.gen_importance_score(max_variables = 2, filename= f\"testing_gen_importance_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<importance_score.dask_parameter_generator at 0x7fe7ac21cb20>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1221989 , 2.53365315, 1.3855913 , 3.10684358, 1.6406857 ,\n",
       "       3.33068119, 2.88993968, 2.53807575, 2.87093464, 3.86139902,\n",
       "       4.15737696, 3.01869696, 2.46967208, 4.97361432, 1.31672618,\n",
       "       2.89329281, 2.78538677, 4.45956039, 3.73578869, 3.98299483,\n",
       "       4.01323186, 5.41843843, 2.50782488, 3.37859475, 3.64404334,\n",
       "       5.70986157, 4.56636235, 4.01544742, 4.64567099, 8.52682878])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_run.find_groupby_means().compute().y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts =  test_run.contrast_generator(max_variables = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the importance score results to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_simulation(sample_size, iter, error_scale, ddf, num_interactions, start_number = None):\n",
    "    for i in range(iter):\n",
    "        subsample = gen_subsample(sample_size, error_scale, ddf)\n",
    "        gen = dask_parameter_generator(subsample)\n",
    "        if start_number:\n",
    "            i += start_number\n",
    "        gen.gen_importance_score(max_variables = 2, filename= f\"importance_score_numInteractions_{num_interactions}_iter_{i}_n_{sample_size}_error_{error_scale}.csv\", dir = os.path.join(os.getcwd(), 'importance_score'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/barcode'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 351/351 [00:17<00:00, 20.26it/s]  \n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/root/barcode/.venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py\", line 426, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\nModuleNotFoundError: No module named 'importance_score'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/barcode/importance_score/gen_importance_score.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/barcode/importance_score/gen_importance_score.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m single_simulation(\u001b[39m1000\u001b[39;49m, \u001b[39miter\u001b[39;49m \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, error_scale \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, ddf \u001b[39m=\u001b[39;49m df, num_interactions \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m, start_number \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32m/root/barcode/importance_score/gen_importance_score.ipynb Cell 14\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/barcode/importance_score/gen_importance_score.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m start_number:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/barcode/importance_score/gen_importance_score.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m start_number\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/root/barcode/importance_score/gen_importance_score.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m gen\u001b[39m.\u001b[39;49mgen_importance_score(max_variables \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m, filename\u001b[39m=\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mimportance_score_numInteractions_\u001b[39;49m\u001b[39m{\u001b[39;49;00mnum_interactions\u001b[39m}\u001b[39;49;00m\u001b[39m_iter_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m_n_\u001b[39;49m\u001b[39m{\u001b[39;49;00msample_size\u001b[39m}\u001b[39;49;00m\u001b[39m_error_\u001b[39;49m\u001b[39m{\u001b[39;49;00merror_scale\u001b[39m}\u001b[39;49;00m\u001b[39m.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mdir\u001b[39;49m \u001b[39m=\u001b[39;49m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(os\u001b[39m.\u001b[39;49mgetcwd(), \u001b[39m'\u001b[39;49m\u001b[39mimportance_score\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/barcode/importance_score/../importance_score.py:363\u001b[0m, in \u001b[0;36mdask_parameter_generator.gen_importance_score\u001b[0;34m(self, filename, dir, max_variables)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39m# process the remainder\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(contrast_batch):\n\u001b[0;32m--> 363\u001b[0m     f_test_results \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49mnum_cores)(delayed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_f_test)(c, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m contrast_batch)\n\u001b[1;32m    364\u001b[0m     f_test_results \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcdf \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m f_test_results]\n\u001b[1;32m    365\u001b[0m     rows \u001b[39m=\u001b[39m [c\u001b[39m.\u001b[39msum(axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mtolist()[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m [f] \u001b[39mfor\u001b[39;00m c,f \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(contrast_batch, f_test_results)]\n",
      "File \u001b[0;32m~/barcode/.venv/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m~/barcode/.venv/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/barcode/.venv/lib/python3.10/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[39m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[39m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[39m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[39m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_error_fast()\n\u001b[1;32m   1700\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[39m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/barcode/.venv/lib/python3.10/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[39m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[39m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[39m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[39mif\u001b[39;00m error_job \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     error_job\u001b[39m.\u001b[39;49mget_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout)\n",
      "File \u001b[0;32m~/barcode/.venv/lib/python3.10/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[39m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[39m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[39m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_return_or_raise()\n\u001b[1;32m    738\u001b[0m \u001b[39m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/barcode/.venv/lib/python3.10/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
     ]
    }
   ],
   "source": [
    "single_simulation(1000, iter = 1, error_scale = 1, ddf = df, num_interactions = 2, start_number = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

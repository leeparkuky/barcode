{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f30b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# sys.path.append('/root/barcode/')\n",
    "sys.path.append('../')\n",
    "from BarcodeScanner import tree_and_clustering, base_barcode\n",
    "from itertools import product, combinations\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import timeit\n",
    "from datasets import Dataset\n",
    "\n",
    "def gen_X(num_var: int, sample_size : int):\n",
    "    data_dictionary = {}\n",
    "    for i in range(num_var):\n",
    "        var_name = \"x\" + f\"{i + 1}\"\n",
    "        data_dictionary[var_name] = list(np.random.binomial(1, .5, sample_size))\n",
    "    return pd.DataFrame(data_dictionary)\n",
    "\n",
    "def gen_full_X(num_var: int, sample_size :int):\n",
    "    raw_X = gen_X(num_var = num_var, sample_size = sample_size)\n",
    "    colnames = raw_X.columns\n",
    "    for k in range(2, len(colnames)+ 1):\n",
    "        interaction_generator = combinations(colnames, k)\n",
    "        for interaction_tuple in interaction_generator:\n",
    "            new_colname = \"*\".join(interaction_tuple)\n",
    "            raw_X[new_colname] = raw_X[list(interaction_tuple)].apply(np.prod, axis = 1)\n",
    "    return raw_X\n",
    "\n",
    "def gen_barcode_dataloader(num_var:int, sample_size:int):\n",
    "    raw_X = gen_X(num_var = num_var, sample_size = sample_size)\n",
    "    colnames = [\n",
    "        f\"x{i+1}\" for i in range(num_var)\n",
    "    ]\n",
    "    from datasets import Dataset\n",
    "\n",
    "    dataset = Dataset.from_pandas(raw_X)\n",
    "    def gen_z(examples):\n",
    "        example_list = [examples[x] for x in colnames]\n",
    "        df = pd.DataFrame(zip(*example_list), columns= colnames)\n",
    "        barcodes = base_barcode.gen_barcode(df).reshape(-1).tolist()\n",
    "        y = df.apply(lambda seq: 1 + seq.x1 + seq.x2 + seq.x1*seq.x3 + np.random.normal(), axis = 1).tolist()\n",
    "        return {\"z\": barcodes, \"y\":y}\n",
    "    dataset = dataset.map(gen_z, batched = True, remove_columns=colnames)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b194bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def L(p):\n",
    "    all_sets = list(set(product([0,1], repeat = p))); all_sets.sort()\n",
    "    return np.array([base_barcode.barcode_to_beta(x) for x in all_sets]).astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc57ecb",
   "metadata": {},
   "source": [
    "### Experiment 1: Memory consumption on entire pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b9667d",
   "metadata": {},
   "source": [
    "#### linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1709334",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, n = 5, 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "875e4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =gen_full_X(p, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8d5396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.normal(size = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de1aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0b493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad856213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2f9ec2",
   "metadata": {},
   "source": [
    "#### neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de664e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, n = 5, 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ebf06af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65c376d56844ae8ab00ca1d2a9807fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dataset = gen_barcode_dataloader(p, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d06c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = input_dataset.train_test_split(test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fea40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(input_dataset['train'], batch_size=126, shuffle=True)\n",
    "test_dataloader = DataLoader(input_dataset['test'], batch_size=126, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ba2066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Lasso_Barcode(nn.Module):\n",
    "    def __init__(self, num_variable):\n",
    "        super().__init__()\n",
    "        barcode_size = 2**num_variable\n",
    "        embedding_weights = torch.from_numpy(L(num_variable).astype(float))\n",
    "        self.embedding = nn.Embedding(barcode_size, barcode_size)\n",
    "        self.embedding.weight = nn.Parameter(embedding_weights.to(torch.float32), requires_grad = False)\n",
    "        self.linear = nn.Linear(barcode_size, 1, bias = False, dtype = torch.float32)\n",
    "\n",
    "    def l1_reg(self):\n",
    "        return torch.abs(self.linear.weight).sum()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.linear(x)\n",
    "        return x, self.l1_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae60506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso_Barcode(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a3c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lasso.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49329175",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4b5a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "val_loss = np.inf\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    lasso.train()\n",
    "    for batch in train_dataloader:\n",
    "        input_tensor = batch['z']\n",
    "        output_tensor = batch['y'].to(torch.float32)\n",
    "#         optimizer.zero_grad()\n",
    "        assert input_tensor.size() == output_tensor.size()\n",
    "    \n",
    "\n",
    "        outputs, l1_reg = lasso(input_tensor)\n",
    "        # loss = criterion(outputs, output_feature)\n",
    "        \n",
    "        loss = criterion(outputs, output_tensor) + alpha * l1_reg  # Total loss with L1 regularization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        lasso.eval()\n",
    "        losses = []\n",
    "        for batch in test_dataloader:\n",
    "            input_tensor = batch['z']\n",
    "            output_tensor = batch['y'].to(torch.float32)\n",
    "            assert input_tensor.size() == output_tensor.size()\n",
    "            outputs, l1_reg = lasso(input_tensor)\n",
    "            loss = criterion(outputs, output_tensor) + alpha * l1_reg  # Total loss with L1 regularization\n",
    "            losses.append(loss.item())\n",
    "        current_val_loss = np.mean(losses)\n",
    "        if val_loss > current_val_loss:\n",
    "            val_loss = current_val_loss\n",
    "        else:\n",
    "            break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4d6adc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.0701e+00, -1.8711e-01,  2.9036e-01,  1.8416e-01,  1.8360e-01,\n",
       "          3.2203e-01,  5.1909e-02, -5.3827e-02,  2.6595e-01, -7.7950e-02,\n",
       "         -3.6562e-02,  2.6297e-01, -1.9794e-03, -9.1933e-02, -4.0277e-01,\n",
       "          4.0053e-01,  1.5431e-01, -1.6806e-01, -1.5014e-01, -1.3885e-01,\n",
       "          1.1912e-01,  4.4234e-01, -1.5886e-01,  4.8904e-01, -3.0276e-01,\n",
       "         -2.8123e-03,  8.0175e-02, -9.3240e-02, -3.1572e-01, -1.1820e-01,\n",
       "         -1.2660e-01,  3.0994e-01]], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e3703",
   "metadata": {},
   "source": [
    "This time, please use the \"from memory_profiler import profile\" and profile decorator and run the python script and manually check the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1240ce29",
   "metadata": {},
   "source": [
    "### Experiment 2: Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8b0f8",
   "metadata": {},
   "source": [
    "Choose the proper early stopping criteria for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dcb9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
